{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of this assignment, we will create and analyze time series of creation dates of Stack Overflow questions. This assignment is to be completed **INDIVIDUALLY** and it is due on **October 7 at 7pm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some time series from the data. You may choose to analyze either users or tags. To analyze users, take the top 100 users with the most question posts. For each user, your time series will be the number of questions posted by that user at some frequency. To analyze tags, take the top 100 most popular question tags. For each tag, your time series will be the number of questions with that tag at some frequency. You may choose to sample your data each week, each month, on a certain day of the week or at certain hours in a day depending on what trend you are hoping to find in the data. For example, if you choose to analyze tags and sample during different hours of the day, your hypothesis could be that languages (i.e. Javascript) that are used more in industry will have more questions posted during work hours, whereas languages (i.e. Python) that are taught in academia will have more questions posted after midnight when students are scrambling to finish their homework.\n",
    "\n",
    "Compare the time series using one of the methods discussed in class. In a few paragraphs, write down what you were hoping to find in the data, what timeseries you created, what method you chose and why. **(30 pts)**\n",
    "\n",
    "You may find the [pandas.DataFrame.resample](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) module helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import xml.etree.ElementTree as ET\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "from math import sqrt\n",
    "\n",
    "questions = pd.DataFrame()\n",
    "\n",
    "N = 100\n",
    "tag_count = {}\n",
    "\n",
    "\n",
    "for event, element in ET.iterparse('stackoverflow-posts-2015.xml'):\n",
    "    \n",
    "    if element.attrib['PostTypeId'] == '1':\n",
    "        try:\n",
    "            res = {}\n",
    "            res['Id'] = [element.attrib['Id']]\n",
    "            res['CreationDate'] = [element.attrib['CreationDate']]\n",
    "            tag = element.attrib['Tags'][:element.attrib['Tags'].find('>')+1]\n",
    "            res['Tags'] = [tag]\n",
    "            res_df = pd.DataFrame(res)\n",
    "            questions = questions.append(res_df)\n",
    "            if tag not in tag_count:\n",
    "                tag_count[tag] = 0\n",
    "            tag_count[tag] += 1\n",
    "            \n",
    "        except KeyError:\n",
    "            pass\n",
    "            \n",
    "top_tags = [''] * N\n",
    "top_freq = [0] * N\n",
    "            \n",
    "for tag in tag_count:\n",
    "    if tag_count[tag] > min(top_freq):\n",
    "        i = top_freq.index(min(top_freq))\n",
    "        top_tags[i] = tag\n",
    "        top_freq[i] = tag_count[tag]\n",
    "\n",
    "time_series2 = pd.DataFrame(0, index = list(range(24)), columns = top_tags)\n",
    "\n",
    "for tag in top_tags:\n",
    "    for dt in questions.loc[questions['Tags'] == tag]['CreationDate'].tolist():\n",
    "        prev = time_series2.at[int(dt[11:13]), tag]\n",
    "        time_series2.xs(int(dt[11:13]))[tag] = prev+1\n",
    "\n",
    "def cosine_similarity(l1, l2):\n",
    "    p_sum = 0\n",
    "    l1_sum = 0\n",
    "    l2_sum = 0\n",
    "    for i in range(len(l1)):\n",
    "        p_sum += l1[i] * l2[i]\n",
    "        l1_sum += l1[i] * l1[i]\n",
    "        l2_sum += l2[i] * l2[i]\n",
    "    res = p_sum / (sqrt(l1_sum * l2_sum))\n",
    "    return res\n",
    "\n",
    "similarities = {}\n",
    "for col1 in top_tags:\n",
    "    for col2 in top_tags:\n",
    "        if col1 != col2:\n",
    "            if (col2, col1) not in similarities:\n",
    "                cl1 = time_series2[col1].tolist()\n",
    "                cl2 = time_series2[col2].tolist()\n",
    "                similarities[(col1, col2)] = cosine_similarity(cl1, cl2)\n",
    "\n",
    "print('By cosine similarity, %s is the most similar tag pair.\\n%s is the most dissimilar tag pair.' \n",
    "      % (str(max(similarities, key=similarities.get)), str(min(similarities, key=similarities.get))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a different distance/similarity metric and repeat the same time series analysis. Compare the two different metrics you used. **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidian_distance(l1, l2):\n",
    "    res = 0\n",
    "    for i in range(len(l1)):\n",
    "        p = l1[i] - l2[i]\n",
    "        res += p*p\n",
    "    return sqrt(res)\n",
    "\n",
    "distances = {}\n",
    "for col1 in top_tags:\n",
    "    for col2 in top_tags:\n",
    "        if col1 != col2:\n",
    "            if (col2, col1) not in distances:\n",
    "                cl1 = time_series2[col1].tolist()\n",
    "                cl2 = time_series2[col2].tolist()\n",
    "                distances[(col1, col2)] = euclidian_distance(cl1, cl2)\n",
    "                \n",
    "print('By euclidian distance, %s is the most similar tag pair.\\n%s is the most dissimilar tag pair.' \n",
    "      % (str(max(distances, key=distances.get)), str(min(distances, key=distances.get))))\n",
    "      \n",
    "sim_dist = {}\n",
    "max_sim = max(similarities.values())\n",
    "max_dist = max(distances.values())\n",
    "\n",
    "for tag_pair in similarities:\n",
    "    sim_dist[tag_pair] = [similarities[tag_pair]/max_sim, distances[tag_pair]/max_dist]\n",
    "\n",
    "difference = sum([sim_dist[tp][0]/sim_dist[tp][1] for tp in similarities])/N\n",
    "\n",
    "print('The difference between the two metrics is %s. (Same metrics would produce 1)' % str(difference))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
